# TrackTx-NF: Nascent RNA Analysis Pipeline

<div align="center">

**üß¨ A powerful, user-friendly Nextflow pipeline for analyzing nascent RNA sequencing data**

[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A525.04.0-23aa62.svg)](https://www.nextflow.io/)
[![Docker](https://img.shields.io/badge/docker-supported-0db7ed.svg)](https://www.docker.com/)
[![Conda](https://img.shields.io/badge/conda-supported-green.svg)](https://conda.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[**Quick Start**](#-quick-start) ‚Ä¢
[**Features**](#-features) ‚Ä¢
[**Installation**](#Ô∏è-installation) ‚Ä¢
[**Usage**](#-usage) ‚Ä¢
[**Documentation**](#-documentation)

</div>

---

## üöÄ Quick Start

Get up and running in **under 5 minutes**:

### 1. **Install Docker** (2 minutes)
```bash
# Download Docker Desktop: https://docs.docker.com/get-docker/
# Or use your system package manager
```

### üì° Live Monitoring (nf-monitor)

TrackTx ships with a terminal UI monitor for live, per-task insight during runs.

```bash
# In the pipeline working directory (where .nextflow.log is produced)
python3 nfmon.py \
  --log .nextflow.log \
  --trace results/trace/trace.txt \
  --refresh 0.8

# Minimal mode if you only have the trace file
python3 nfmon.py --trace results/trace/trace.txt --from-start

# One-shot summary (prints a snapshot and exits)
python3 nfmon.py --trace results/trace/trace.txt --oneshot

# Export JSON snapshot to a file (updates atomically)
python3 nfmon.py --trace results/trace/trace.txt --oneshot --json nfmon.json
```

What you get:
- Live list of running tasks with PID, CPU%, memory (RSS), age, and stage hints
- Total pipeline progress, cumulative completed/failed/cached counts
- Live log tail for the focused task (or all running tasks with `--all-logs`)
- System stats (CPU/MEM/LOAD), approximate cores-in-use

Useful flags:
- `--filter "<regex>"`: show only processes matching a name pattern
- `--all-logs`: stack live logs of all running tasks in the UI
- `--log-rows N`: preferred height for the live log panel in the Rich UI
- `--retain-sec N`: keep finished tasks visible for N seconds (0 = clear immediately)
- `--from-start`: ingest full history instead of tailing current run only

Keyboard hints (Rich/curses UI):
- j/k: move focus ‚Ä¢ f: filter by process ‚Ä¢ s: sort ‚Ä¢ +/- and ]/[ : log/tail size ‚Ä¢ a: toggle all-logs ‚Ä¢ q: quit

### 2. **Clone & Prepare** (1 minute)
```bash
git clone https://github.com/SerhatAktay/TrackTx.git
cd TrackTx
# Generate config & sample sheet using the built-in generator
# 1) Open the generator in your browser
open TrackTx_config_generator.html   # macOS (or double-click the file)
# 2) Fill in your study details
# 3) Click Export to save: params.yaml and samplesheet.csv
```

### 3. **Run Pipeline** (30 seconds to start)
```bash
./run_pipeline.sh --params-file params.yaml --samplesheet samplesheet.csv
# üéâ That's it! The pipeline uses your generated inputs and handles the rest
```

### 4. **View Results**
```bash
# Open the interactive report
open results/reports/tracktx_combined_report.html

# Load tracks in genome browser
ls results/03_genome_tracks/*.bw
```

---

## üß¨ What is TrackTx-NF?

TrackTx-NF analyzes **nascent RNA sequencing data** to understand real-time gene transcription dynamics. Unlike traditional RNA-seq that captures steady-state RNA levels, nascent RNA-seq captures newly synthesized RNA, providing insights into active transcription processes.

### üî¨ Scientific Applications

Perfect for studying:
- **üî• Heat shock responses** and stress biology
- **üíä Drug treatments** and compound screening  
- **‚è±Ô∏è Transcription kinetics** and gene regulation
- **üß¨ RNA Polymerase II** behavior and pausing
- **üîÑ Divergent transcription** from promoters
- **üß™ Developmental transitions** and cell fate

### üìä Analysis Workflow

```mermaid
graph LR
    A[üìÅ FASTQ Files] --> B[‚úÇÔ∏è Read Processing]
    B --> C[üß≠ Genome Alignment]
    C --> D[üìà Track Generation]
    D --> E[üîÑ Divergent Detection]
    E --> F[‚öñÔ∏è Normalization]
    F --> G[üìä Interactive Reports]
```

1. **üìÅ Read Processing** ‚Üí Adapter trimming, UMI/barcode handling, quality control
2. **üß≠ Genome Alignment** ‚Üí Optimized Bowtie2 mapping with spike-in support
3. **üìà Track Generation** ‚Üí Strand-specific coverage tracks (bedGraph/BigWig)
4. **üîÑ Divergent Detection** ‚Üí Identifies bidirectional transcription events
5. **‚öñÔ∏è Normalization** ‚Üí CPM and spike-in normalization for quantitative comparisons
6. **üìä Interactive Reports** ‚Üí Professional HTML dashboards with advanced visualizations

---

## ‚ú® Features

### üîß **Universal Compatibility**
- **üñ•Ô∏è Any System**: Laptops, workstations, servers, HPC clusters, cloud
- **‚ö° Smart Scaling**: Automatically adapts from 1-CPU to 100+ CPU systems
- **üê≥ Container-Ready**: All software included via Docker - no installation hassles
- **üêç Conda Support**: Automatic environment setup when Docker unavailable
- **‚òÅÔ∏è Cloud-Native**: AWS, Google Cloud, Azure compatible

### üéõÔ∏è **Intelligent Operation**
- **ü§ñ Auto-Detection**: Automatically detects and optimizes for your environment
- **üìä Adaptive Resources**: Optimizes CPU/memory allocation based on system capabilities
- **üéØ Smart Defaults**: Works immediately with sensible parameters
- **üîß Easy Customization**: Simple YAML configuration for advanced users
- **üîÑ Resume Support**: Intelligent checkpoint/resume for long-running analyses

### üìà **Advanced Analysis**
- **üß™ Flexible Input**: Single-end and paired-end sequencing data
- **üß¨ Multi-Genome**: Human (hs1), mouse (mm39), fly (dm6), plant genomes, custom references
- **üè∑Ô∏è UMI/Barcode Support**: Molecular identifiers and sample demultiplexing
- **üìè Spike-in Normalization**: Quantitative cross-sample comparisons using external controls
- **üìä Rich Visualizations**: Interactive plots, heatmaps, and genome browser tracks
- **üìã Comprehensive QC**: Detailed quality control metrics and validation

---

## üèóÔ∏è Installation

> **üí° No Sudo/Admin Access?** This pipeline works perfectly without root privileges!  
> Just needs: Nextflow + Conda (both installable to your home directory, no admin required).

### **Option 1: Docker** (Recommended)
```bash
# 1. Install Docker Desktop
# https://docs.docker.com/get-docker/

# 2. Clone and run
git clone https://github.com/SerhatAktay/TrackTx.git
cd TrackTx
# Generate params.yaml & samplesheet.csv via TrackTx_config_generator.html, then:
./run_pipeline.sh --params-file params.yaml --samplesheet samplesheet.csv
```

### **Option 2: Conda** (No sudo required)
```bash
# 1. Install Miniconda (to your home directory - no sudo needed)
# https://docs.conda.io/en/latest/miniconda.html

# 2. Clone and run
git clone https://github.com/SerhatAktay/TrackTx.git
cd TrackTx
# Generate params.yaml & samplesheet.csv via TrackTx_config_generator.html, then:
./run_pipeline.sh --params-file params.yaml --samplesheet samplesheet.csv
```

**Note:** The conda profile also works with mamba/micromamba if you have them installed (faster solving).

### **Option 3: Manual Installation**
```bash
# Install dependencies (see envs/tracktx.yaml for full list):
# - nextflow (‚â•25.04.0)
# - bowtie2, samtools, bedtools, bedGraphToBigWig
# - python3, umi_tools, cutadapt, fastqc

git clone https://github.com/SerhatAktay/TrackTx.git
cd TrackTx
./run_pipeline.sh -profile local
```

---

## üöÄ Usage

### **Basic Usage**
```bash
# Default analysis (auto-detects environment)
# Recommended: explicitly provide your generated files
./run_pipeline.sh --params-file params.yaml --samplesheet samplesheet.csv

# With custom sample sheet
./run_pipeline.sh --samplesheet my_samples.csv

# With custom parameters
./run_pipeline.sh --params-file my_params.yaml

# Resume interrupted run
./run_pipeline.sh --resume

# Preview commands without running
./run_pipeline.sh --dry-run
```

### **Input Files**

#### **Sample Sheet** (`samplesheet.csv`)
```csv
sample_id,condition,timepoint,replicate,file
ctrl_rep1,control,0,1,data/ctrl_rep1.fastq
ctrl_rep2,control,0,2,data/ctrl_rep2.fastq
heat_rep1,treatment,30,1,data/heat_rep1.fastq
heat_rep2,treatment,30,2,data/heat_rep2.fastq
```

### QC options (fastp default)

You can choose which QC tool to run during input preparation and whether to QC raw inputs in addition to final reads.

```yaml
# params.yaml
qc:
  tool: fastp   # fastp | fastqc | none
fastqc_raw: true # also QC raw inputs (respects qc.tool)
```

- fastp (default): faster, single-pass QC with modern HTML and machine-readable JSON.
- fastqc: classic FastQC modules; slower. The pipeline prints a warning about speed.
- none: skip QC entirely (the pipeline writes small README notes under `fastqc_raw/` and `fastqc_final/`).

Outputs under `01_trimmed_fastq/<sample>/`:
- If `qc.tool: fastp`:
  - `fastqc_raw/fastp_raw.{html,json}` when `fastqc_raw: true`
  - `fastqc_final/fastp_final.{html,json}` always (unless `qc.tool: none`)
- If `qc.tool: fastqc`:
  - FastQC HTML/zip in the same `fastqc_*` directories.

Fastp vs FastQC (at-a-glance):
- fastp: per-base quality/content, GC, duplication, adapter content (detect/detect_adapter_for_pe), length dist, overrepresented sequences, N content, polyX tails; multithreaded; HTML + JSON.
- FastQC: per-base/per-sequence quality and GC, length dist, duplication, overrepresented sequences, adapter content, k-mer content, per-tile quality; HTML + data zip; slower.

#### **Parameters** (`params.yaml`) - Typically generated
```yaml
# Basic settings
reference_genome: "hs1"      # Human (hs1), Mouse (mm39), Fly (dm6)
paired_end: false           # true for paired-end data
output_dir: "./results"

# Advanced options
adapter_trim:
  enabled: true
  adapter1: "TGGAATTCTCGGGTGCCAAGG"
umi:
  enabled: true
  length: 7
spike_in:
  enabled: true
  genome: "dm6"
divergent_tx:
  enabled: true
  threshold: 1.0
```

### **Example Workflows**

#### **Time-Course Heat Shock Study**
```bash
# Create time course sample sheet
cat > timecourse.csv << EOF
sample_id,condition,timepoint,replicate,file
t0_r1,baseline,0,1,data/timepoint_0_rep1.fastq
t0_r2,baseline,0,2,data/timepoint_0_rep2.fastq
t15_r1,heat_shock,15,1,data/timepoint_15_rep1.fastq
t15_r2,heat_shock,15,2,data/timepoint_15_rep2.fastq
t30_r1,heat_shock,30,1,data/timepoint_30_rep1.fastq
t30_r2,heat_shock,30,2,data/timepoint_30_rep2.fastq
t60_r1,heat_shock,60,1,data/timepoint_60_rep1.fastq
t60_r2,heat_shock,60,2,data/timepoint_60_rep2.fastq
EOF

./run_pipeline.sh --samplesheet timecourse.csv
```

#### **Drug Treatment with Spike-in**
```bash
cat > drug_params.yaml << EOF
reference_genome: "mm39"
spike_in:
  enabled: true
  genome: "dm6"
adapter_trim:
  adapter1: "AGATCGGAAGAGC"
EOF

./run_pipeline.sh --params-file drug_params.yaml
```

#### **Paired-End PRO-seq Analysis**
```bash
cat > proseq_params.yaml << EOF
paired_end: true
umi:
  enabled: false
adapter_trim:
  enabled: true
  adapter1: "TGGAATTCTCGGGTGCCAAGG"
  adapter2: "AGATCGGAAGAGCGGTTCAG"
EOF

./run_pipeline.sh --params-file proseq_params.yaml
```

---

## üìä Outputs

### **Directory Structure**
```
results/
‚îú‚îÄ‚îÄ üìä reports/
‚îÇ   ‚îú‚îÄ‚îÄ tracktx_combined_report.html    # üéØ Main interactive dashboard
‚îÇ   ‚îú‚îÄ‚îÄ execution_report.html           # Pipeline performance metrics
‚îÇ   ‚îî‚îÄ‚îÄ sample_reports/                 # Individual sample QC reports
‚îú‚îÄ‚îÄ üìà 03_genome_tracks/                # Coverage tracks for genome browsers
‚îÇ   ‚îú‚îÄ‚îÄ sample1.3p.pos.bw              # 3' positive strand BigWig
‚îÇ   ‚îú‚îÄ‚îÄ sample1.3p.neg.bw              # 3' negative strand BigWig
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ ‚öñÔ∏è 05_normalized_tracks/            # Quantitative comparison tracks
‚îÇ   ‚îú‚îÄ‚îÄ cpm/                           # Counts per million normalization
‚îÇ   ‚îî‚îÄ‚îÄ sicpm/                         # Spike-in normalized tracks
‚îú‚îÄ‚îÄ üîÑ 06_divergent_tx/                 # Divergent transcription analysis
‚îÇ   ‚îú‚îÄ‚îÄ sample1_divergent_regions.bed  # Detected divergent regions
‚îÇ   ‚îî‚îÄ‚îÄ divergent_summary.tsv          # Summary statistics
‚îú‚îÄ‚îÄ üß¨ 07_functional_regions/          # Functional genomic region assignment
‚îÇ   ‚îú‚îÄ‚îÄ functional_regions.bed         # Annotated regions (BED9)
‚îÇ   ‚îî‚îÄ‚îÄ functional_regions_summary.tsv # Per-category signal totals
‚îú‚îÄ‚îÄ üìä 08_pol2_metrics/                # Pol II metrics and pausing index
‚îú‚îÄ‚îÄ üìã 10_qc/                          # Quality control metrics
‚îÇ   ‚îú‚îÄ‚îÄ qc_strand_bias.tsv            # Strand distribution
‚îÇ   ‚îú‚îÄ‚îÄ qc_pol2.json                  # Comprehensive QC metrics
‚îÇ   ‚îî‚îÄ‚îÄ qc_coverage.tsv               # Coverage statistics
‚îî‚îÄ‚îÄ üìã 04_counts/                      # Read count summaries
```

### **Key Output Files**

| File | Description |
|------|-------------|
| **`tracktx_combined_report.html`** | üéØ Interactive analysis dashboard with plots and tables |
| **`03_genome_tracks/*.bw`** | üìà Load directly in IGV, UCSC Genome Browser, or WashU |
| **`05_normalized_tracks/`** | ‚öñÔ∏è Quantitative tracks for cross-sample comparisons |
| **`06_divergent_tx/*.bed`** | üîÑ Divergent transcription regions and summit coordinates |
| **`execution_report.html`** | üìä Pipeline performance and resource usage analysis |

---

## üîß Configuration Profiles

The pipeline automatically detects your environment, but you can specify profiles manually:

| Profile | Description | When to Use |
|---------|-------------|-------------|
| **`docker`** üê≥ | Everything included, fastest | **Recommended** - Most reliable |
| **`conda`** üêç | Auto environment setup | When Docker unavailable (works with conda/mamba/micromamba) |
| **`local`** üñ•Ô∏è | System-installed tools | Manual tool management |

```bash
./run_pipeline.sh                 # Auto-detect environment
./run_pipeline.sh -profile docker # Force Docker
./run_pipeline.sh -profile conda  # Force Conda
```

---

## üìã Requirements

### **System Requirements**

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **OS** | Linux, macOS, Windows (WSL2) | Linux or macOS |
| **CPU** | 1+ cores | 8+ cores |
| **RAM** | 4+ GB | 16+ GB |
| **Storage** | 50+ GB free | 200+ GB SSD |
| **Software** | Docker OR Conda | Docker Desktop |

### **Pipeline automatically scales** from single-CPU laptops to high-end servers!

---

## üöÄ Performance & Scaling

### **Automatic Resource Optimization**

The pipeline intelligently adapts to your system:

| System Type | CPU Usage | Memory | Typical Runtime* |
|-------------|-----------|--------|------------------|
| **Laptop** (4 cores, 8GB) | 1-4 CPUs | 2-6 GB | 2-4 hours |
| **Workstation** (12 cores, 32GB) | 2-8 CPUs | 4-16 GB | 1-2 hours |
| **Server** (32+ cores, 64GB+) | 4-8 CPUs | 8-32 GB | <1 hour |

*_For typical dataset (10-20M reads per sample)_

### **Performance Tips**
- üöÄ **Use SSD storage** for dramatic I/O improvements
- üê≥ **Docker profile** provides best performance and reliability
- ‚ö° **More CPU cores** = faster alignment and track generation
- üíæ **More RAM** = better caching and reduced disk usage

---

## üîß Troubleshooting

### **Common Issues & Solutions**

<details>
<summary><b>‚ùå "Docker not found" or "Docker daemon not running"</b></summary>

**Solution:**
```bash
# Install Docker Desktop: https://docs.docker.com/get-docker/
# Make sure Docker Desktop is running
# Test: docker --version
```
</details>

<details>
<summary><b>‚ùå "Sample sheet not found"</b></summary>

**Solution:**
```bash
# Create sample sheet in correct location
echo "sample_id,condition,timepoint,replicate,file" > samplesheet.csv
echo "sample1,control,0,1,data/sample1.fastq" >> samplesheet.csv
```
</details>

<details>
<summary><b>‚ùå "Out of memory" errors (exit 137)</b></summary>

**Solution:**
```bash
# Pipeline auto-adapts, but for very large datasets:
export NXF_HOST_MEM=32  # Force 32GB memory limit
./run_pipeline.sh

# Or use fewer parallel processes:
export NXF_HOST_CPUS=4  # Limit to 4 CPUs
./run_pipeline.sh
```
</details>

<details>
<summary><b>‚ùå "Conda environment creation failed"</b></summary>

**Solution:**
```bash
# Use Docker instead (more reliable):
./run_pipeline.sh -profile docker

# Or clean conda cache:
conda clean --all --yes
./run_pipeline.sh
```
</details>

<details>
<summary><b>‚ùå Pipeline seems very slow</b></summary>

**Reasons & Solutions:**
- **First run**: Downloads reference genomes (normal, ~10-30 min)
- **Large dataset**: Expected for >50M reads per sample
- **Limited resources**: Pipeline adapts but takes longer
- **I/O bottleneck**: Use SSD storage for work directory
</details>

<details>
<summary><b>‚ö†Ô∏è High "Non-localized Polymerase" percentage (>20%)</b></summary>

**Expected**: 5-10% for well-annotated genomes (human, mouse)

**If you see >20%, check:**

1. **Genome assembly mismatch** ‚Üê Most common cause
   ```bash
   # Ensure FASTQ data matches reference genome
   # Example: hg38 data requires hg38 reference (not hg19)
   ```

2. **Incomplete annotation**
   ```bash
   # Use comprehensive GTF (e.g., GENCODE comprehensive, not basic)
   # Verify annotation matches genome assembly version
   ```

3. **Sample quality issues**
   ```bash
   # Check duplication rate (<30% expected)
   # Review QC reports in results/10_qc/
   # Look for adapter contamination in FastQC
   ```

4. **Wrong library type**
   - PRO-seq, ChIP-seq: 5-10% expected
   - GRO-seq: 10-15% acceptable
   - Total RNA-seq: NOT appropriate for this pipeline

**See [docs/FUNCTIONAL_REGIONS.md](docs/FUNCTIONAL_REGIONS.md) for detailed troubleshooting.**
</details>

### **Getting Help**
1. üìä **Check execution report**: `results/execution_report.html`
2. üìã **Review pipeline logs**: `.nextflow.log`
3. üîç **Examine work directories**: `work/*/`
4. üí¨ **GitHub Discussions**: [Discussions](https://github.com/SerhatAktay/TrackTx/discussions)
5. üêõ **Report bugs**: [Issues](https://github.com/SerhatAktay/TrackTx/issues)

---

## üß¨ Scientific Background

### **Nascent RNA-seq vs Traditional RNA-seq**

| Aspect | Traditional RNA-seq | Nascent RNA-seq |
|--------|-------------------|-----------------|
| **RNA Captured** | Steady-state total RNA | Newly synthesized RNA |
| **Time Resolution** | Hours to days | Minutes to hours |
| **Labeling** | None | Metabolic (4sU, 6sU, BrU) |
| **Insights** | Gene expression levels | Real-time transcription rates |

### **Key Experimental Steps**
1. **üß™ Metabolic Labeling**: Cells incorporate modified nucleotides (4sU/6sU/BrU)
2. **‚è±Ô∏è Time Course**: Sample at multiple time points after stimulus
3. **üß≤ RNA Isolation**: Biotin-streptavidin pulldown of labeled RNA
4. **üß¨ Library Prep**: Standard RNA-seq library preparation
5. **üìä Analysis**: TrackTx-NF pipeline for comprehensive analysis

### **Applications in Research**
- **üî• Stress Biology**: Heat shock, oxidative stress, osmotic stress
- **üíä Pharmacology**: Drug mechanism of action, dose-response studies
- **üß™ Development**: Cell fate transitions, differentiation programs
- **ü¶† Disease**: Cancer progression, neurodegeneration, inflammation
- **üî¨ Basic Biology**: Transcription factor function, chromatin regulation

---

## üìñ Documentation

### **Core Documentation**
- **[FUNCTIONAL_REGIONS.md](docs/FUNCTIONAL_REGIONS.md)** - Detailed guide to functional region classification
  - Hierarchical assignment logic
  - Expected percentage ranges
  - Quality control guidelines
  - Troubleshooting high non-localized readings
  
- **[CPU_ALLOCATION_GUIDE.md](docs/CPU_ALLOCATION_GUIDE.md)** - Performance optimization guide
  - Resource allocation strategies
  - Throughput vs latency tradeoffs
  - System-specific recommendations

- **[BUGFIX_SUMMARY.md](BUGFIX_SUMMARY.md)** - Recent fixes and improvements
  - Critical bug fixes (functional regions, QC module)
  - Expected changes in results
  - How to apply updates

### **Interactive Tools**
- **[TrackTx_config_generator.html](TrackTx_config_generator.html)** - Web-based configuration generator
  - Point-and-click parameter setup
  - Generates validated `params.yaml`
  - Includes documentation for all options

---

## üìö Citation & References

### **How to Cite TrackTx-NF**
```bibtex
@software{tracktx_nf,
  title = {TrackTx-NF: A comprehensive Nextflow pipeline for nascent RNA sequencing analysis},
  author = {Serhat Aktay and Contributors},
  year = {2025},
  url = {https://github.com/SerhatAktay/TrackTx},
  doi = {10.5281/zenodo.XXXXXX}  # Will be assigned upon publication
}
```

### **Key References**
- **Nascent RNA-seq methods**: [Core et al., 2008](https://doi.org/10.1126/science.1162228)
- **PRO-seq technique**: [Kwak et al., 2013](https://doi.org/10.1038/nmeth.2478)
- **4sU-seq protocol**: [Rabani et al., 2011](https://doi.org/10.1038/nmeth.1582)
- **Divergent transcription**: [Scruggs et al., 2015](https://doi.org/10.1371/journal.pgen.1005387)

### **Pipeline Components**
- **Nextflow**: [Di Tommaso et al., 2017](https://doi.org/10.1038/nbt.3820)
- **Bowtie2**: [Langmead & Salzberg, 2012](https://doi.org/10.1038/nmeth.1923)
- **bedtools**: [Quinlan & Hall, 2010](https://doi.org/10.1093/bioinformatics/btq033)
- **UMI-tools**: [Smith et al., 2017](https://doi.org/10.1101/gr.209601.116)

---

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md).

### **Ways to Contribute**
- üêõ **Report bugs** via [GitHub Issues](https://github.com/your-username/TrackTx/issues)
- ‚ú® **Request features** via [GitHub Discussions](https://github.com/your-username/TrackTx/discussions)
- üìñ **Improve documentation** with pull requests
- üß™ **Add test datasets** and validation cases
- üîß **Contribute code** via pull requests

### **Development Setup**
```bash
git clone https://github.com/your-username/TrackTx.git
cd TrackTx

# Run tests
./run_pipeline.sh --dry-run

# Contribute your changes
git checkout -b feature-branch
# Make changes...
git commit -m "Add feature X"
git push origin feature-branch
# Open pull request
```

---

## üìú License

TrackTx-NF is released under the [MIT License](LICENSE).

---

## üôè Acknowledgments

- **Nextflow Community** for the amazing workflow framework
- **nf-core** for best practices and inspiration
- **Bioconda** for comprehensive software packaging
- **Docker** for containerization technology
- **All contributors** who make this project better

---

<div align="center">

**üß¨ Happy analyzing! TrackTx-NF makes nascent RNA analysis simple, powerful, and reproducible.**

‚≠ê **Star this repo** if TrackTx-NF is useful for your research!

[**Documentation**](https://github.com/SerhatAktay/TrackTx/wiki) ‚Ä¢
[**Discussions**](https://github.com/SerhatAktay/TrackTx/discussions) ‚Ä¢
[**Issues**](https://github.com/SerhatAktay/TrackTx/issues) ‚Ä¢
[**Releases**](https://github.com/SerhatAktay/TrackTx/releases)

</div>